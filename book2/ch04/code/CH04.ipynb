{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4abe25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:48:00.553169Z",
     "start_time": "2023-10-11T06:48:00.541155Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ce87a",
   "metadata": {},
   "source": [
    "# word2vec 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e52836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:48:01.197286Z",
     "start_time": "2023-10-11T06:48:01.191286Z"
    }
   },
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "\n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4912d2d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:48:01.385076Z",
     "start_time": "2023-10-11T06:48:01.371076Z"
    }
   },
   "outputs": [],
   "source": [
    "class EmbeddingDot:\n",
    "    def __init__(self, W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, h, idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = np.sum(target_W * h, axis=1)\n",
    "\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = dout.reshape(dout.shape[0], 1)\n",
    "\n",
    "        dtarget_W = dout * h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout * target_W\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f24eac4f-8b85-49c7-90dc-48c3b29fc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from common.layers import Embedding, SigmoidWithLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f106ca14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:48:01.556990Z",
     "start_time": "2023-10-11T06:48:01.538998Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnigramSampler:\n",
    "    def __init__(self, corpus, power, sample_size):\n",
    "        self.sample_size = sample_size\n",
    "        self.vocab_size = None\n",
    "        self.word_p = None\n",
    "\n",
    "        counts = collections.Counter()\n",
    "        for word_id in corpus:\n",
    "            counts[word_id] += 1\n",
    "\n",
    "        vocab_size = len(counts)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.word_p = np.zeros(vocab_size)\n",
    "        for i in range(vocab_size):\n",
    "            self.word_p[i] = counts[i]\n",
    "\n",
    "        self.word_p = np.power(self.word_p, power)\n",
    "        self.word_p /= np.sum(self.word_p)\n",
    "\n",
    "    def get_negative_sample(self, target):\n",
    "        batch_size = target.shape[0]\n",
    "\n",
    "        if not GPU:\n",
    "            negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                p = self.word_p.copy()\n",
    "                target_idx = target[i]\n",
    "                p[target_idx] = 0\n",
    "                p /= p.sum()\n",
    "                negative_sample[i, :] = np.random.choice(self.vocab_size, size=self.sample_size, replace=False, p=p)\n",
    "        else:\n",
    "            # GPU(cupy）로 계산할 때는 속도를 우선한다.\n",
    "            # 부정적 예에 타깃이 포함될 수 있다.\n",
    "            negative_sample = np.random.choice(self.vocab_size, size=(batch_size, self.sample_size),\n",
    "                                               replace=True, p=self.word_p)\n",
    "\n",
    "        return negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46122816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:48:01.728145Z",
     "start_time": "2023-10-11T06:48:01.707492Z"
    }
   },
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss:\n",
    "    def __init__(self, W, corpus, power=0.75, sample_size=5):\n",
    "        self.sample_size = sample_size\n",
    "        self.sampler = UnigramSampler(corpus, power, sample_size)\n",
    "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size + 1)]\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, h, target):\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.sampler.get_negative_sample(target)\n",
    "\n",
    "        # 긍정적 예 순전파\n",
    "        score = self.embed_dot_layers[0].forward(h, target)\n",
    "        correct_label = np.ones(batch_size, dtype=np.int32)\n",
    "        loss = self.loss_layers[0].forward(score, correct_label)\n",
    "\n",
    "        # 부정적 예 순전파\n",
    "        negative_label = np.zeros(batch_size, dtype=np.int32)\n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:, i]\n",
    "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
    "            loss += self.loss_layers[1 + i].forward(score, negative_label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dh = 0\n",
    "        for l0, l1 in zip(self.loss_layers, self.embed_dot_layers):\n",
    "            dscore = l0.backward(dout)\n",
    "            dh += l1.backward(dscore)\n",
    "\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdabb7",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48641905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:48:02.591792Z",
     "start_time": "2023-10-11T06:48:02.578899Z"
    }
   },
   "outputs": [],
   "source": [
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)  # Embedding 계층 사용\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "\n",
    "        # 모든 가중치와 기울기를 배열에 모은다.\n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f39b98c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:48:03.139405Z",
     "start_time": "2023-10-11T06:48:03.119400Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8419531b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T06:50:34.445824Z",
     "start_time": "2023-10-11T06:50:34.402771Z"
    }
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "window_size = 5\n",
    "hidden_size = 10\n",
    "batch_size = 10\n",
    "max_epoch = 1\n",
    "\n",
    "# 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee851a6b-2f7a-403f-b246-e4521de4b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import config\n",
    "from common.util import create_contexts_target, to_cpu, to_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5683b7a2-f968-4f1e-b8d8-20cdb2b87866",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "if config.GPU:\n",
    "    contexts, target = to_gpu(contexts), to_gpu(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42d563cb-fb82-41e2-a9df-f29db7b0083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28cdd9f0-3c28-4b22-9dee-832a16ad7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 등 생성\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "# model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35a56c6b-9de6-48ac-8792-9860bafecec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a079a755-d600-4ef0-b4f4-a0310ad6f760",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습 시작\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "# 나중에 사용할 수 있도록 필요한 데이터 저장\n",
    "word_vecs = model.word_vecs\n",
    "if config.GPU:\n",
    "    word_vecs = to_cpu(word_vecs)\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0783be3-2691-48cf-8b2a-ce253453208c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkl_file = 'cbow_params.pkl'  # or 'skipgram_params.pkl'\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825d81f-ffbb-4e83-bfea-36e9a7d469c3",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0bc7c5d-d0f3-4053-ac14-5c085a9b8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.util import most_similar, analogy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42038352-47cb-4610-a99d-c5ef54ab466b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " we: 0.97998046875\n",
      " too: 0.978515625\n",
      " very: 0.97802734375\n",
      " 're: 0.97802734375\n",
      " i: 0.9755859375\n",
      "\n",
      "[query] year\n",
      " remaining: 0.96435546875\n",
      " dividend: 0.96240234375\n",
      " day: 0.96142578125\n",
      " wage: 0.9599609375\n",
      " stake: 0.95751953125\n",
      "\n",
      "[query] car\n",
      " building: 0.97412109375\n",
      " strike: 0.97314453125\n",
      " oak: 0.96728515625\n",
      " system: 0.9658203125\n",
      " foundation: 0.96533203125\n",
      "\n",
      "[query] toyota\n",
      " chevrolet: 0.9833984375\n",
      " mart: 0.97705078125\n",
      " eugene: 0.97265625\n",
      " shell: 0.966796875\n",
      " reebok: 0.96533203125\n"
     ]
    }
   ],
   "source": [
    "pkl_file = 'cbow_params.pkl'\n",
    "# pkl_file = 'skipgram_params.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    word_vecs = params['word_vecs']\n",
    "    word_to_id = params['word_to_id']\n",
    "    id_to_word = params['id_to_word']\n",
    "\n",
    "# 가장 비슷한(most similar) 단어 뽑기\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7f3436b-34b6-4729-9881-6f1ca2a6adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "[analogy] king:man = queen:?\n",
      " know: 3.314453125\n",
      " going: 3.119140625\n",
      " do: 3.052734375\n",
      " think: 3.05078125\n",
      " problem: 3.025390625\n",
      "\n",
      "[analogy] take:took = go:?\n",
      " chief: 3.611328125\n",
      " officer: 3.599609375\n",
      " president: 3.439453125\n",
      " executive: 3.3046875\n",
      " vice: 3.203125\n",
      "\n",
      "[analogy] car:cars = child:?\n",
      " addition: 3.6171875\n",
      " revenue: 3.474609375\n",
      " yield: 3.328125\n",
      " volume: 2.966796875\n",
      " yen: 2.904296875\n",
      "\n",
      "[analogy] good:better = bad:?\n",
      " <eos>: 4.9140625\n",
      " composite: 3.0859375\n",
      " exchange: 2.240234375\n",
      " quarter: 2.15625\n",
      " york: 1.9921875\n"
     ]
    }
   ],
   "source": [
    "# 유추(analogy) 작업\n",
    "print('-'*50)\n",
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
